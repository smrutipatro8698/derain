# -*- coding: utf-8 -*-
"""cgan1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TAE2GZBREIAuUBL7vBVSStUxG5f2MCXy
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow as tf
import numpy as np
import datetime
import time
import functions
import os
import matplotlib.pyplot as plt
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

app = "drive/My Drive/ADAS_EE6132/Codes/cgan/model1"
bpp = "drive/My Drive/ADAS_EE6132/Data/synthetic_data/resize_jaad1/"
cpp = "drive/My Drive/ADAS_EE6132/Data/synthetic_data/resize_clean/"

input_path = bpp   # the path of rainy images
gt_path = cpp       # the path of ground truth

input_files = os.listdir(input_path)
gt_files = os.listdir(gt_path) 
input_files.sort()
gt_files.sort()

batch_size = 5
epochs=1000

lambda_a = 0.5                          #GAN coefficient
lambda_p = 0.012                      #vgg coefficient
lambda_e = 15                         #raw coefficient

discrminator_learning_rate = 0.002
generator_learning_rate = 0.0002
beta1 = 0.5

label_switch_frequency = 5

total_images = len(input_files)
print(total_images)
input_files[9]

filename_list = []
for i in range(total_images):
  name = bpp + input_files[i]
  filename_list.append(name)

dataset = tf.compat.v1.data.Dataset.from_tensor_slices(filename_list)
dataset = dataset.map(functions.load_img)
#dataset = dataset.shuffle(buffer_size=10000)
load_img = dataset.batch(batch_size)
load_img = load_img.prefetch(buffer_size=10000)
iterator = load_img.make_initializable_iterator()
batch_of_imgs = iterator.get_next()

batch_of_imgs[0]# 1080 1920 3

fileground_list = []
for i in range(total_images):
  name = cpp + gt_files[i]
  fileground_list.append(name)
gdataset = tf.compat.v1.data.Dataset.from_tensor_slices(fileground_list)
gdataset = gdataset.map(functions.load_img)
#gdataset = gdataset.shuffle(buffer_size=10000)
gload_img = gdataset.batch(batch_size)
gload_img = gload_img.prefetch(buffer_size=10000)
giterator = gload_img.make_initializable_iterator()
gbatch_of_imgs = giterator.get_next()

gbatch_of_imgs[:,:,:,:]

gbatch_of_imgs[0]# 224 448 3
wi = 270
ht = 480

batch_sizes = tf.placeholder(tf.int32)
derain_placeholder = tf.placeholder(tf.float32, shape=(batch_size,wi,ht,3))
rain_placeholder = tf.placeholder(tf.float32, shape=(batch_size,wi,ht,3))


d_watch_placeholder = tf.placeholder(tf.float32)
g_watch_placeholder = tf.placeholder(tf.float32)


img_ground_truth_for_vgg16 = tf.placeholder(tf.float32, shape=(batch_size,wi,ht,3))


D_Loss_placeholder = tf.placeholder(tf.float32)
G_Loss_placeholder = tf.placeholder(tf.float32)

Gz = functions.generator(rain_placeholder,batch_size)

fake = tf.concat([Gz, rain_placeholder], 3)
real = tf.concat([derain_placeholder, rain_placeholder], 3)

Dg = functions.discriminator(fake)            #for generated image and groumd truth
Dg_truth = functions.discriminator(real)

vgg19_features_output_gen = functions.vgg_19(Gz)
vgg19_features_gt = functions.vgg_19(derain_placeholder)

L_E = tf.reduce_mean( 1 * ((tf.abs(tf.math.subtract(derain_placeholder,Gz)))))
L_A = tf.reduce_mean(-1 * tf.math.log(tf.clip_by_value(tf.math.sigmoid(Dg), 1e-10, 1)))
L_P = tf.reduce_mean( 1 * ((tf.abs(tf.math.subtract(vgg19_features_output_gen,vgg19_features_gt)))))

L_RP = lambda_e * L_E + lambda_a*L_A + lambda_p * L_P

g_loss = L_RP

d_loss = tf.reduce_mean((tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg, dtype=tf.float32) ) + tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg_truth, labels = tf.ones_like(Dg_truth, dtype=tf.float32) )))

d_loss_flip = tf.reduce_mean((tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg, dtype=tf.float32) ) + tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg_truth, labels = tf.zeros_like(Dg_truth, dtype=tf.float32) )))

tvars = tf.global_variables()


gen_vars = [var for var in tf.trainable_variables() if var.name.startswith("generator")]

d_vars = [var for var in tf.trainable_variables() if var.name.startswith("discriminator")]

sess = tf.Session()


tf.summary.scalar('d_weight_watch', d_watch_placeholder)
tf.summary.scalar('g_weight_watch', g_watch_placeholder)

tf.summary.scalar('Generator_loss', g_loss)
tf.summary.scalar('Discriminator_loss', d_loss)

tf.summary.scalar('Raw_loss', L_E)
tf.summary.scalar('VGG_loss', L_P)
tf.summary.scalar('GAN_loss', L_A)

output_img = tf.summary.image('Output', Gz, max_outputs = 1)                     #record the input image
target_img = tf.summary.image('Target', derain_placeholder, max_outputs = 1)     #record the generator output image
input_img = tf.summary.image('Input', rain_placeholder, max_outputs = 1)         #record the ground truth image


tf.summary.merge([output_img, target_img, input_img])


merged = tf.summary.merge_all()
logdir = "drive/My Drive/ADAS_EE6132/Codes/cgan/model1/tensorboard/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S") + "/"
writer = tf.summary.FileWriter(logdir, sess.graph)


#print out trainable parameters
print (d_vars)
print (gen_vars)


#define optimizer

d_trainer = tf.train.GradientDescentOptimizer(discrminator_learning_rate)             # discriminator use SGD

gradients_of_discriminator = d_trainer.compute_gradients(d_loss, d_vars)
d_train = d_trainer.apply_gradients(gradients_of_discriminator)

gradients_of_discriminator_flip = d_trainer.compute_gradients(d_loss_flip, d_vars)
d_train_flip = d_trainer.apply_gradients(gradients_of_discriminator_flip)


g_trainer = tf.train.AdamOptimizer(generator_learning_rate,beta1 = beta1)                           # generator use Adam
gradients_of_generator = g_trainer.compute_gradients(g_loss, gen_vars)
g_train = g_trainer.apply_gradients(gradients_of_generator)


saver = tf.train.Saver()

epochs = 1
n = batch_size
newsize = (270, 480) 
with tf.Session() as sess:

  sess.run(tf.global_variables_initializer())

  for i in range(epochs):
    print(i)
    sess.run([iterator.initializer, giterator.initializer])
    j=0
    try:
     while True:
      print(i, j)
      j = j +1

      current_itertion = int((i * (700 / batch_size)) + j)  # 700 is the image number of training dataset
      print("current_iteration", current_itertion)
      train_img, train_gt = sess.run([batch_of_imgs,gbatch_of_imgs])                   #set the batch input images
      randomize = np.arange(n)
      np.random.shuffle(randomize)
      train_img_rain = train_img[randomize]
      train_img_ground_truth = train_gt[randomize]
      print(np.shape(train_img_rain))


      # train discriminator
      # if counter the label_switch_frequency, the discriminator will use the switched label to update the weight
      print("Apple")
      if current_itertion % label_switch_frequency != 0:
        _ = sess.run([d_train], {rain_placeholder: train_img_rain, batch_sizes: batch_size, derain_placeholder:train_img_ground_truth})
      else:
        _ = sess.run([d_train_flip], {rain_placeholder: train_img_rain, batch_sizes: batch_size, derain_placeholder:train_img_ground_truth})

      # train generator

      _ = sess.run([g_train], {rain_placeholder: train_img_rain, batch_sizes: batch_size, derain_placeholder:train_img_ground_truth})

      #print("Banana")
      # record the specicfic weight to watch its change

      g_watch_vars = [var for var in tf.trainable_variables() if  "generator/gen_v_e6_w:0" in var.name]

      d_watch_vars = [var for var in tf.trainable_variables() if "discriminator/d_w4:0" in var.name]
      #print("Coffee")

      gen_watch, d_watch = sess.run([g_watch_vars, d_watch_vars], {rain_placeholder: train_img_rain, batch_sizes: batch_size, derain_placeholder:train_img_ground_truth})


      print ('gen_watch' + str(gen_watch[0][0][0][0][0]))
      print ('d_watch' + str(d_watch[0][0][0][0][0]))


      # record to tensorboard      

      summary = sess.run(merged, {rain_placeholder: train_img_rain, batch_sizes: batch_size, derain_placeholder:train_img_ground_truth, d_watch_placeholder:d_watch[0][0][0][0][0], g_watch_placeholder:gen_watch[0][0][0][0][0]})

      writer.add_summary(summary, current_itertion)

      # print the current iteration
      print ('Batch : ' + str(current_itertion))




    except tf.errors.OutOfRangeError:

      # we save the whole model every epoch

      save_path = saver.save(sess, 'drive/My Drive/ADAS_EE6132/Codes/cgan/model1/model.ckpt')





import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('drive/My Drive/ADAS_EE6132/Data/synthetic_data/resize_jaad1/image1 copy.jpg')
imgplot = plt.imshow(img)
plt.show()

np.shape(img)

image=train_img_rain[0,:,:,:] #my_img.eval()
print(image.shape)
plt.imshow(image)
# Image.fromarray(np.asarray(image)).show()

# my_img = tf.image.decode_jpeg(gbatch_of_imgs[0,:,:,:])

image=train_img_ground_truth[0,:,:,:] #my_img.eval()
print(image.shape)
plt.imshow(image)

from PIL import Image  
uuu = "drive/My Drive/ADAS_EE6132/"
cpp = "drive/My Drive/ADAS_EE6132/Data/synthetic_data/jaad_1/"
ppp = "drive/My Drive/ADAS_EE6132/Data/synthetic_data/resize_jaad1/"
input_path = cpp   # the path of rainy images

input_files = os.listdir(input_path)

filename_list = []
for i in range(total_images):
  name =  input_files[i]
  filename_list.append(name)

# Opens a image in RGB mode  
k =0
print(k)
im = Image.open(cpp+filename_list[k])  

# Size of the image in pixels (size of orginal image)  
# (This is not mandatory)  
width, height = im.size  
  
# Setting the points for cropped image  

newsize = (480, 480) 
im1 = im.resize(newsize) 
# Shows the image in image viewer  
im1.show()
im1.save(uuu+"demo.jpeg", "JPEG", optimize=True)

width

im1
